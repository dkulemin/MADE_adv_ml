{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import re\n",
    "import time\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "from scipy import sparse\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import scipy.stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('results.pkl', 'rb') as results_file:\n",
    "    raw_results = pickle.load(results_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('tournaments.pkl', 'rb') as tournaments_file:\n",
    "    raw_tournaments = pickle.load(tournaments_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('players.pkl', 'rb') as players_file:\n",
    "    raw_players = pickle.load(players_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Задание 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Прочитайте и проанализируйте данные, выберите турниры, в которых есть данные о составах команд и повопросных результатах (поле mask в results.pkl). \n",
    "\n",
    "Для унификации предлагаю:\n",
    "\n",
    "* взять в тренировочный набор турниры с dateStart из 2019 года; \n",
    "\n",
    "* в тестовый — турниры с dateStart из 2020 года.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Начнем с того, что из raw_results выкинем все турниры раньше 2019 года, содержащие данные о составах комманд и повопросные результаты."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5528/5528 [00:01<00:00, 3565.70it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "847"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tournament_keys = [v['id'] for k, v in raw_tournaments.items() if v['dateStart'][:4] == '2019' or v['dateStart'][:4] == '2020']\n",
    "\n",
    "for key in tqdm(list(raw_results.keys())):\n",
    "    if key not in tournament_keys or raw_results[key] == [] or not raw_results[key][0].get('mask', None) or raw_results[key][0]['mask'] == None:\n",
    "        raw_results.pop(key, None)\n",
    "        \n",
    "len(raw_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Удалим команды с масками ответов не равными максимальной в соревновании, удалим вопросы с пометкой `X` и заменим вопросы с пометкой `?` на `0`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_if_mask_empty(results):\n",
    "    #Проверка на наличие маски в результатах\n",
    "    for tournament, teams in results.items():\n",
    "        for team in teams:\n",
    "            if not team['mask']:\n",
    "                return True\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_if_mask_small(results):\n",
    "    #проверка длины маски в соревновании\n",
    "    for tournament, teams in results.items():\n",
    "        max_mask_lengt = 0\n",
    "        for team in teams:\n",
    "            if team['mask'] and len(team['mask']) > max_mask_lengt:\n",
    "                max_mask_lengt = len(team['mask'])\n",
    "        for team in teams:\n",
    "            if team['mask'] and len(team['mask']) < max_mask_lengt:\n",
    "                return True\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_X_in_masks(results):\n",
    "    #Проверка на наличие 'X' в результатах\n",
    "    for tournament, teams in results.items():\n",
    "        for team in teams:\n",
    "            if team['mask'] and 'X' in team['mask']:\n",
    "                return True\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_qmark_in_masks(results):\n",
    "    #Проверка на наличие '?' в результатах\n",
    "    for tournament, teams in results.items():\n",
    "        for team in teams:\n",
    "            if team['mask'] and '?' in team['mask']:\n",
    "                return True\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_masks(results):\n",
    "    for tournament, teams in tqdm(results.items()):\n",
    "        max_mask_lengt = 0\n",
    "        #удалим из масок 'X' и заменим '?' на '0', а так же найдем максимальную маску в соревновании\n",
    "        for team in teams:\n",
    "            if team['mask'] and 'X' in team['mask']:\n",
    "                team['mask'] = team['mask'].replace('X', '')\n",
    "            if team['mask'] and '?' in team['mask']:\n",
    "                team['mask'] = team['mask'].replace('?', '0')\n",
    "            if team['mask'] and len(team['mask']) > max_mask_lengt:\n",
    "                max_mask_lengt = len(team['mask'])\n",
    "        #удалим команды с пустыми полями 'mask' и с короткими масками\n",
    "        for idx, team in list(enumerate(teams))[::-1]:\n",
    "            if not team['mask'] or len(team['mask']) < max_mask_lengt:\n",
    "                teams.pop(idx)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Запустим чекеры до очистки данных:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "True\n",
      "True\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "print(check_if_mask_empty(raw_results))\n",
    "print(check_if_mask_small(raw_results))\n",
    "print(check_X_in_masks(raw_results))\n",
    "print(check_qmark_in_masks(raw_results))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Запустим процесс очистки:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 847/847 [00:00<00:00, 2602.34it/s]\n"
     ]
    }
   ],
   "source": [
    "clean_masks(raw_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь чекеры не находят проблем:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "False\n",
      "False\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "print(check_if_mask_empty(raw_results))\n",
    "print(check_if_mask_small(raw_results))\n",
    "print(check_X_in_masks(raw_results))\n",
    "print(check_qmark_in_masks(raw_results))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Составим обучающую и тестовую выборки по турнирам:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 847/847 [00:00<00:00, 1035.39it/s]\n"
     ]
    }
   ],
   "source": [
    "tournaments_train = []\n",
    "tournaments_test = []\n",
    "\n",
    "for tournament_id in tqdm(raw_results.keys()):\n",
    "    tournament = dict()\n",
    "    tournament['id'] = tournament_id\n",
    "    teams_list = []\n",
    "    for team in raw_results[tournament_id]:\n",
    "        team_info = dict()\n",
    "        team_info['id'] = team['team']['id']\n",
    "        team_info['mask'] = team['mask']\n",
    "        team_info['players'] = [member['player']['id'] for member in team['teamMembers']]\n",
    "        teams_list.append(team_info)\n",
    "    tournament['teams'] = teams_list\n",
    "    \n",
    "    if raw_tournaments[tournament_id]['dateStart'][:4] == '2019':\n",
    "        tournaments_train.append(tournament)\n",
    "    else:\n",
    "        tournaments_test.append(tournament)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('tournaments_train.json', 'w') as fout:\n",
    "    json.dump(tournaments_train, fout)\n",
    "    \n",
    "with open('tournaments_test.json', 'w') as fout:\n",
    "    json.dump(tournaments_test, fout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('tournaments_train.json') as fin:\n",
    "    tournaments_train = json.load(fin)\n",
    "    \n",
    "with open('tournaments_test.json') as fin:\n",
    "    tournaments_test = json.load(fin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(674, 173)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tournaments_train), len(tournaments_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Удалим исходные данные:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "del raw_results, raw_tournaments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Задание 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Постройте baseline-модель на основе линейной или логистической регрессии, которая будет обучать рейтинг-лист игроков. Замечания и подсказки:\n",
    "* повопросные результаты — это фактически результаты броска монетки, и их предсказание скорее всего имеет отношение к бинарной классификации;\n",
    "* в разных турнирах вопросы совсем разного уровня сложности, поэтому модель должна это учитывать; скорее всего, модель должна будет явно обучать не только силу каждого игрока, но и сложность каждого вопроса;\n",
    "* для baseline-модели можно забыть о командах и считать, что повопросные результаты команды просто относятся к каждому из её игроков."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Присвоим каждому `id` игрока порядковый номер:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 674/674 [00:00<00:00, 6906.58it/s]\n"
     ]
    }
   ],
   "source": [
    "players = set()\n",
    "\n",
    "for tournament in tqdm(tournaments_train):\n",
    "    for team in tournament['teams']:\n",
    "        for player in team['players']:\n",
    "            players.add(player)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "id_to_player = {i: p for i, p in enumerate(players)}\n",
    "player_to_id = {p: i for i, p in id_to_player.items()}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Составим таблицу повопросных ответов игроков размерности (все игроки + все вопросы) * (повопросные ответы).\n",
    "\n",
    "Целевая переменная - правильность ответа (`0` или `1`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 674/674 [00:14<00:00, 48.08it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 13.6 s, sys: 465 ms, total: 14.1 s\n",
      "Wall time: 14 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "player_ids = []\n",
    "question_ids = []\n",
    "y_labels = []\n",
    "\n",
    "team_ids = []\n",
    "\n",
    "questions_start_index = len(player_to_id)\n",
    "for tournament in tqdm(tournaments_train):\n",
    "    for team in tournament['teams']:\n",
    "        team_mask = team['mask']\n",
    "        for q, answer in enumerate(team_mask, questions_start_index):\n",
    "            for player in team['players']:\n",
    "                player_ids.append(player_to_id[player])\n",
    "                question_ids.append(q)\n",
    "                y_labels.append(int(answer))\n",
    "                \n",
    "                team_ids.append(team['id'])\n",
    "                \n",
    "    questions_start_index += len(team_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = np.array(y_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 49 s, sys: 8.92 s, total: 57.9 s\n",
      "Wall time: 57.8 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(17751584, 90656)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "X_train = sparse.lil_matrix((len(player_ids), questions_start_index), dtype=int)\n",
    "X_train[range(len(player_ids)), player_ids] = 1\n",
    "X_train[range(len(player_ids)), question_ids] = 1\n",
    "\n",
    "len(player_ids), questions_start_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "sparse.save_npz('X_train_matrix.npz', X_train.tocoo())\n",
    "np.savetxt('y_train_vec.txt', y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = sparse.load_npz('X_train_matrix.npz')\n",
    "y_train = np.loadtxt('y_train_vec.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((17751584, 90656), (17751584,))"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, y_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обучим на полученных данных логистическую регрессию:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model = LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4min 39s, sys: 2min 42s, total: 7min 21s\n",
      "Wall time: 4min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dkulemin/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "base_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('base_model', 'wb') as fout:\n",
    "    pickle.dump(base_model, fout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('base_model', 'rb') as fin:\n",
    "    base_model = pickle.load(fin)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В качестве рейтинга игроков возьмем первые коэффициенты модели:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "player_rating = base_model.coef_[0][:len(player_to_id)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Составим рейтинг лист игроков:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "rating_table = []\n",
    "\n",
    "for i, rating in enumerate(player_rating):\n",
    "    player_id = id_to_player[i]\n",
    "    rating_table.append([rating, player_id, raw_players[player_id]['name'] + ' ' + raw_players[player_id]['surname']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rating</th>\n",
       "      <th>player id</th>\n",
       "      <th>player name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.791533</td>\n",
       "      <td>27403</td>\n",
       "      <td>Максим Руссо</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3.635847</td>\n",
       "      <td>4270</td>\n",
       "      <td>Александра Брутер</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.397761</td>\n",
       "      <td>30152</td>\n",
       "      <td>Артём Сорожкин</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.387160</td>\n",
       "      <td>28751</td>\n",
       "      <td>Иван Семушин</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.320266</td>\n",
       "      <td>27822</td>\n",
       "      <td>Михаил Савченков</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>3.261366</td>\n",
       "      <td>30270</td>\n",
       "      <td>Сергей Спешков</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>3.197049</td>\n",
       "      <td>20691</td>\n",
       "      <td>Станислав Мереминский</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>3.184139</td>\n",
       "      <td>34328</td>\n",
       "      <td>Михаил Царёв</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>3.158918</td>\n",
       "      <td>37047</td>\n",
       "      <td>Мария Юнгер</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>3.158539</td>\n",
       "      <td>18036</td>\n",
       "      <td>Михаил Левандовский</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>3.129191</td>\n",
       "      <td>3843</td>\n",
       "      <td>Светлана Бомешко</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>3.128260</td>\n",
       "      <td>56647</td>\n",
       "      <td>Наталья Горелова</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>3.104622</td>\n",
       "      <td>22935</td>\n",
       "      <td>Илья Новиков</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>3.093651</td>\n",
       "      <td>216863</td>\n",
       "      <td>Глеб Гаврилов</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>3.089993</td>\n",
       "      <td>22799</td>\n",
       "      <td>Сергей Николенко</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>3.067932</td>\n",
       "      <td>7008</td>\n",
       "      <td>Алексей Гилёв</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>3.057887</td>\n",
       "      <td>9061</td>\n",
       "      <td>Евгений Дёмин</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>3.051666</td>\n",
       "      <td>16332</td>\n",
       "      <td>Николай Крапиль</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>3.045103</td>\n",
       "      <td>27622</td>\n",
       "      <td>Николай Рябых</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>3.044481</td>\n",
       "      <td>38196</td>\n",
       "      <td>Артём Митрофанов</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>3.042967</td>\n",
       "      <td>18332</td>\n",
       "      <td>Александр Либер</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>3.019503</td>\n",
       "      <td>5483</td>\n",
       "      <td>Иван Веселов</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>3.018905</td>\n",
       "      <td>1585</td>\n",
       "      <td>Юлия Архангельская</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>3.005570</td>\n",
       "      <td>222188</td>\n",
       "      <td>Арина Гринко</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>2.992967</td>\n",
       "      <td>74001</td>\n",
       "      <td>Игорь Мокин</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>2.985704</td>\n",
       "      <td>505</td>\n",
       "      <td>Иделия Айзятулова</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>2.976112</td>\n",
       "      <td>16837</td>\n",
       "      <td>Наталья Кудряшова</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>2.975165</td>\n",
       "      <td>19915</td>\n",
       "      <td>Александр Марков</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>2.960505</td>\n",
       "      <td>15727</td>\n",
       "      <td>Александр Коробейников</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>2.957829</td>\n",
       "      <td>34846</td>\n",
       "      <td>Антон Чернин</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      rating  player id             player name\n",
       "0   3.791533      27403            Максим Руссо\n",
       "1   3.635847       4270       Александра Брутер\n",
       "2   3.397761      30152          Артём Сорожкин\n",
       "3   3.387160      28751            Иван Семушин\n",
       "4   3.320266      27822        Михаил Савченков\n",
       "5   3.261366      30270          Сергей Спешков\n",
       "6   3.197049      20691   Станислав Мереминский\n",
       "7   3.184139      34328            Михаил Царёв\n",
       "8   3.158918      37047             Мария Юнгер\n",
       "9   3.158539      18036     Михаил Левандовский\n",
       "10  3.129191       3843        Светлана Бомешко\n",
       "11  3.128260      56647        Наталья Горелова\n",
       "12  3.104622      22935            Илья Новиков\n",
       "13  3.093651     216863           Глеб Гаврилов\n",
       "14  3.089993      22799        Сергей Николенко\n",
       "15  3.067932       7008           Алексей Гилёв\n",
       "16  3.057887       9061           Евгений Дёмин\n",
       "17  3.051666      16332         Николай Крапиль\n",
       "18  3.045103      27622           Николай Рябых\n",
       "19  3.044481      38196        Артём Митрофанов\n",
       "20  3.042967      18332         Александр Либер\n",
       "21  3.019503       5483            Иван Веселов\n",
       "22  3.018905       1585      Юлия Архангельская\n",
       "23  3.005570     222188            Арина Гринко\n",
       "24  2.992967      74001             Игорь Мокин\n",
       "25  2.985704        505       Иделия Айзятулова\n",
       "26  2.976112      16837       Наталья Кудряшова\n",
       "27  2.975165      19915        Александр Марков\n",
       "28  2.960505      15727  Александр Коробейников\n",
       "29  2.957829      34846            Антон Чернин"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rating_list = pd.DataFrame(sorted(rating_table, reverse=True), columns=['rating', 'player id', 'player name'])\n",
    "rating_list.head(30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Задание 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Качество рейтинг-системы оценивается качеством предсказаний результатов турниров. Но сами повопросные результаты наши модели предсказывать вряд ли смогут, ведь неизвестно, насколько сложными окажутся вопросы в будущих турнирах; да и не нужны эти предсказания сами по себе. Поэтому:\n",
    "* предложите способ предсказать результаты нового турнира с известными составами, но неизвестными вопросами, в виде ранжирования команд;\n",
    "* в качестве метрики качества на тестовом наборе давайте считать ранговые корреляции Спирмена и Кендалла (их можно взять в пакете scipy) между реальным ранжированием в результатах турнира и предсказанным моделью, усреднённые по тестовому множеству турниров.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Оценим позицию команды в рейтинге, исходя из вероятности того, что хотябы один игрок команды правильно ответил на вопрос."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для начала посчитаем число правильных ответов в командах:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 173/173 [00:00<00:00, 785.35it/s]\n"
     ]
    }
   ],
   "source": [
    "tournaments_answers_count = []\n",
    "\n",
    "for tournament in tqdm(tournaments_test):\n",
    "    teams_answers_count = []\n",
    "    for team in tournament['teams']:  \n",
    "        test_player_ids = [player_to_id[player] for player in team['players'] if player in player_to_id.keys()]\n",
    "        if len(test_player_ids):\n",
    "            team_answers = list(map(int, team['mask']))\n",
    "            teams_answers_count.append(sum(team_answers))\n",
    "    tournaments_answers_count.append(teams_answers_count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь предскажем рейтинги команд, интересующие вероятности расчитаем по формуле:\n",
    "\n",
    "$$P(team=1) = 1 - \\prod P(player=0)$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 173/173 [00:12<00:00, 13.56it/s]\n"
     ]
    }
   ],
   "source": [
    "tournaments_rating_pred = []\n",
    "for torunament in tqdm(tournaments_test):\n",
    "    preds = []\n",
    "    for team in torunament['teams']:\n",
    "        test_player_ids = [player_to_id[player] for player in team['players'] if player in player_to_id.keys()]\n",
    "        if len(test_player_ids):\n",
    "            X = sparse.lil_matrix((len(test_player_ids), questions_start_index), dtype=int)\n",
    "            X[range(len(test_player_ids)), test_player_ids] = 1\n",
    "\n",
    "            fail_probas = base_model.predict_proba(X)[:, 0]\n",
    "            team_proba = 1 - fail_probas.prod()\n",
    "            preds.append(team_proba)\n",
    "    tournaments_rating_pred.append(preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Расчитаем коеффициенты корреляции:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Корреляция Спирмена: 0.7631\n",
      "Корреляция Кендалла: 0.6084\n"
     ]
    }
   ],
   "source": [
    "spearmanr_corrs = []\n",
    "kendall_corrs = []\n",
    "for i in range(len(tournaments_answers_count)):\n",
    "    if len(tournaments_answers_count[i]) > 1:\n",
    "        spearman = scipy.stats.spearmanr(tournaments_answers_count[i], tournaments_rating_pred[i]).correlation\n",
    "        kendall = scipy.stats.kendalltau(tournaments_answers_count[i], tournaments_rating_pred[i]).correlation\n",
    "        spearmanr_corrs.append(spearman)\n",
    "        kendall_corrs.append(kendall)\n",
    "print(f'Корреляция Спирмена: {np.mean(spearmanr_corrs):.4f}')\n",
    "print(f'Корреляция Кендалла: {np.mean(kendall_corrs):.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Задание 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь главное: ЧГК — это всё-таки командная игра. Поэтому:\n",
    "* предложите способ учитывать то, что на вопрос отвечают сразу несколько игроков; скорее всего, понадобятся скрытые переменные; не стесняйтесь делать упрощающие предположения, но теперь переменные “игрок X ответил на вопрос Y” при условии данных должны стать зависимыми для игроков одной и той же команды;\n",
    "* разработайте EM-схему для обучения этой модели, реализуйте её в коде;\n",
    "* обучите несколько итераций, убедитесь, что целевые метрики со временем растут (скорее всего, ненамного, но расти должны), выберите лучшую модель, используя целевые метрики.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
